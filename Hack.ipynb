{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI6eywRIn73eZIwWT+1Adf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanshuman021/HandSigns/blob/master/Hack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQRg4Ney86bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnet_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKdBHPoZcIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4NnKNru6mBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'data.zip'\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGLoDH_17l9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "11f917d8-13ee-4c56-c57f-c46a428bfaff"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'data/validation',\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1999 images belonging to 10 classes.\n",
            "Found 70 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nThKp5GcQs9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"cp.ckpt\"\n",
        "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath= checkpoint_path,save_weights_only=True,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR78Qd52XlF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmGmC8LcP_d9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(loss,val_loss):\n",
        "    plt.figure()\n",
        "    plt.plot(loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuracy(acc,val_acc):\n",
        "    plt.figure()\n",
        "    plt.plot(acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Test'],loc='upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcac28udP_6c",
        "colab_type": "text"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, input_shape=(100, 100, 3), kernel_size=11,strides=(4,4),\n",
        "                 activation = \"relu\",padding=\"same\"))\n",
        "model.add(MaxPool2D(pool_size = (3,3),strides = (2,2),padding=\"same\"))\n",
        "model.add(Conv2D(45, kernel_size =3,activation='relu',padding=\"same\"))\n",
        "model.add(MaxPool2D(pool_size=(3,3),padding=\"same\"))\n",
        "model.add(Conv2D(30, kernel_size=2,activation = \"relu\",padding=\"valid\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(25,activation='relu'))\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(15,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oefm2M6ewow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDcAMxr5exBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm2OagmHexNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape=(100, 100, 3), classes=6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIsRWm2Eex5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_shape=(100, 100, 3), classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPNfbWqufM89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7EMtScKikrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57bf1670-6dfc-4a94-9ce1-a415fecdaf20"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 106, 106, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 50, 50, 64)   9472        zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 50, 50, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 50, 50, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 24, 24, 64)   0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 24, 24, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 24, 24, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 24, 24, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 24, 24, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 24, 24, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 24, 24, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 24, 24, 256)  16640       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 24, 24, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 24, 24, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 24, 24, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 24, 24, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 24, 24, 64)   16448       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 24, 24, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 24, 24, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 24, 24, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 24, 24, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 24, 24, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 24, 24, 256)  16640       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 24, 24, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 24, 24, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 24, 24, 64)   16448       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 24, 24, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 24, 24, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 24, 24, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 24, 24, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 24, 24, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 24, 24, 256)  16640       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 24, 24, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 24, 24, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 12, 12, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 12, 12, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 12, 12, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 6, 6, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 6, 6, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 6, 6, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 6, 6, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 6, 6, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 6, 6, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 6, 6, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 6, 6, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 6, 6, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 6, 6, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 6, 6, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 6, 6, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 6, 6, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 6, 6, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 6, 6, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 6, 6, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 6, 6, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 6, 6, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 6, 6, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 6, 6, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 6, 6, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 6, 6, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 3, 3, 512)    524800      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 3, 3, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 3, 3, 512)    2359808     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 3, 3, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 3, 3, 2048)   1050624     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 3, 3, 2048)   2099200     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 3, 3, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 3, 3, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 3, 3, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 3, 3, 512)    1049088     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 3, 3, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 3, 3, 512)    2359808     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 3, 3, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 3, 3, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 3, 3, 2048)   1050624     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 3, 3, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 3, 3, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 3, 3, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 3, 3, 512)    1049088     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 3, 3, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 3, 3, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 3, 3, 512)    2359808     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 3, 3, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 3, 3, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 3, 3, 2048)   1050624     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 3, 3, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 3, 3, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 3, 3, 2048)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 2, 2, 2048)   0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8192)         0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "fc10 (Dense)                    (None, 10)           81930       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,669,642\n",
            "Trainable params: 23,616,522\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSs2P1U-f_h_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24935565-34a7-4562-a74d-98562b29a730"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=5,\n",
        "    epochs=125,\n",
        "    validation_data=validation_generator,\n",
        "    #callbacks=[modelcheckpoint]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "5/5 [==============================] - 24s 5s/step - loss: 14.6445 - accuracy: 0.0500 - val_loss: 13.9026 - val_accuracy: 0.1143\n",
            "Epoch 2/125\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 10.0817 - accuracy: 0.1312 - val_loss: 4.1405 - val_accuracy: 0.1571\n",
            "Epoch 3/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 5.2153 - accuracy: 0.1437 - val_loss: 5.5327 - val_accuracy: 0.1143\n",
            "Epoch 4/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 4.4726 - accuracy: 0.1187 - val_loss: 4.5460 - val_accuracy: 0.1714\n",
            "Epoch 5/125\n",
            "5/5 [==============================] - 3s 618ms/step - loss: 3.7363 - accuracy: 0.1538 - val_loss: 4.9658 - val_accuracy: 0.2714\n",
            "Epoch 6/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 3.1673 - accuracy: 0.1125 - val_loss: 1.5584 - val_accuracy: 0.1857\n",
            "Epoch 7/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 3.0525 - accuracy: 0.1500 - val_loss: 6.0845 - val_accuracy: 0.2000\n",
            "Epoch 8/125\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 3.5672 - accuracy: 0.2000 - val_loss: 2.6164 - val_accuracy: 0.1000\n",
            "Epoch 9/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 2.9157 - accuracy: 0.1375 - val_loss: 2.5637 - val_accuracy: 0.2143\n",
            "Epoch 10/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 2.7742 - accuracy: 0.2188 - val_loss: 3.0037 - val_accuracy: 0.2857\n",
            "Epoch 11/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 2.3999 - accuracy: 0.2375 - val_loss: 3.6625 - val_accuracy: 0.4000\n",
            "Epoch 12/125\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 2.6952 - accuracy: 0.1813 - val_loss: 1.8677 - val_accuracy: 0.2714\n",
            "Epoch 13/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 2.6997 - accuracy: 0.2188 - val_loss: 3.8210 - val_accuracy: 0.2714\n",
            "Epoch 14/125\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 2.3427 - accuracy: 0.2750 - val_loss: 1.9491 - val_accuracy: 0.4000\n",
            "Epoch 15/125\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 2.2754 - accuracy: 0.2750 - val_loss: 1.3942 - val_accuracy: 0.3429\n",
            "Epoch 16/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 2.1663 - accuracy: 0.3875 - val_loss: 1.3747 - val_accuracy: 0.4429\n",
            "Epoch 17/125\n",
            "5/5 [==============================] - 2s 455ms/step - loss: 1.8800 - accuracy: 0.3357 - val_loss: 1.5542 - val_accuracy: 0.5286\n",
            "Epoch 18/125\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 1.7834 - accuracy: 0.4313 - val_loss: 1.3934 - val_accuracy: 0.5571\n",
            "Epoch 19/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 2.1171 - accuracy: 0.4625 - val_loss: 2.2102 - val_accuracy: 0.5286\n",
            "Epoch 20/125\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 1.9275 - accuracy: 0.4375 - val_loss: 1.5658 - val_accuracy: 0.5143\n",
            "Epoch 21/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 1.6393 - accuracy: 0.4563 - val_loss: 0.9045 - val_accuracy: 0.5000\n",
            "Epoch 22/125\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 1.3976 - accuracy: 0.5188 - val_loss: 2.0944 - val_accuracy: 0.6857\n",
            "Epoch 23/125\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 1.5465 - accuracy: 0.6625 - val_loss: 1.2096 - val_accuracy: 0.6429\n",
            "Epoch 24/125\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 1.4823 - accuracy: 0.5813 - val_loss: 0.8505 - val_accuracy: 0.6286\n",
            "Epoch 25/125\n",
            "5/5 [==============================] - 2s 455ms/step - loss: 1.4055 - accuracy: 0.5562 - val_loss: 1.7968 - val_accuracy: 0.6571\n",
            "Epoch 26/125\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 1.1358 - accuracy: 0.6438 - val_loss: 1.1302 - val_accuracy: 0.6714\n",
            "Epoch 27/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 1.1432 - accuracy: 0.6187 - val_loss: 1.2682 - val_accuracy: 0.6429\n",
            "Epoch 28/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 1.3607 - accuracy: 0.6687 - val_loss: 0.2885 - val_accuracy: 0.7429\n",
            "Epoch 29/125\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 1.0468 - accuracy: 0.5750 - val_loss: 1.0980 - val_accuracy: 0.7000\n",
            "Epoch 30/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 1.0192 - accuracy: 0.6438 - val_loss: 0.3191 - val_accuracy: 0.8143\n",
            "Epoch 31/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.7411 - accuracy: 0.7750 - val_loss: 0.4501 - val_accuracy: 0.8286\n",
            "Epoch 32/125\n",
            "5/5 [==============================] - 2s 451ms/step - loss: 1.0303 - accuracy: 0.7343 - val_loss: 1.8395 - val_accuracy: 0.6571\n",
            "Epoch 33/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.7920 - accuracy: 0.7375 - val_loss: 3.2320 - val_accuracy: 0.7429\n",
            "Epoch 34/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 1.1083 - accuracy: 0.7375 - val_loss: 3.6451 - val_accuracy: 0.6857\n",
            "Epoch 35/125\n",
            "5/5 [==============================] - 2s 456ms/step - loss: 0.9619 - accuracy: 0.7063 - val_loss: 0.4411 - val_accuracy: 0.8286\n",
            "Epoch 36/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.5968 - accuracy: 0.7937 - val_loss: 2.5833 - val_accuracy: 0.7286\n",
            "Epoch 37/125\n",
            "5/5 [==============================] - 2s 448ms/step - loss: 0.8022 - accuracy: 0.7563 - val_loss: 0.6736 - val_accuracy: 0.8143\n",
            "Epoch 38/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.8344 - accuracy: 0.7188 - val_loss: 0.8356 - val_accuracy: 0.8000\n",
            "Epoch 39/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.5525 - accuracy: 0.8313 - val_loss: 1.0673 - val_accuracy: 0.7857\n",
            "Epoch 40/125\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.4934 - accuracy: 0.8438 - val_loss: 0.6678 - val_accuracy: 0.7429\n",
            "Epoch 41/125\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 0.5923 - accuracy: 0.8188 - val_loss: 0.1571 - val_accuracy: 0.7857\n",
            "Epoch 42/125\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.6434 - accuracy: 0.7762 - val_loss: 1.6018 - val_accuracy: 0.7714\n",
            "Epoch 43/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 0.8553 - accuracy: 0.7500 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
            "Epoch 44/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.5522 - accuracy: 0.8313 - val_loss: 1.3453 - val_accuracy: 0.7429\n",
            "Epoch 45/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.8503 - accuracy: 0.7625 - val_loss: 3.0080 - val_accuracy: 0.8571\n",
            "Epoch 46/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.6363 - accuracy: 0.8250 - val_loss: 0.8698 - val_accuracy: 0.7714\n",
            "Epoch 47/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.6731 - accuracy: 0.7937 - val_loss: 0.6604 - val_accuracy: 0.8143\n",
            "Epoch 48/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.7361 - accuracy: 0.7500 - val_loss: 1.2354 - val_accuracy: 0.8571\n",
            "Epoch 49/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.6622 - accuracy: 0.8000 - val_loss: 1.9161 - val_accuracy: 0.8286\n",
            "Epoch 50/125\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 0.5346 - accuracy: 0.8125 - val_loss: 1.8885 - val_accuracy: 0.8429\n",
            "Epoch 51/125\n",
            "5/5 [==============================] - 2s 445ms/step - loss: 0.5937 - accuracy: 0.8182 - val_loss: 0.6835 - val_accuracy: 0.8714\n",
            "Epoch 52/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.3931 - accuracy: 0.8750 - val_loss: 0.9934 - val_accuracy: 0.8000\n",
            "Epoch 53/125\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.6291 - accuracy: 0.8000 - val_loss: 0.2359 - val_accuracy: 0.8429\n",
            "Epoch 54/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.7300 - accuracy: 0.7437 - val_loss: 0.7620 - val_accuracy: 0.9000\n",
            "Epoch 55/125\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 0.6493 - accuracy: 0.8313 - val_loss: 0.6121 - val_accuracy: 0.7714\n",
            "Epoch 56/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.6758 - accuracy: 0.8188 - val_loss: 0.1290 - val_accuracy: 0.8286\n",
            "Epoch 57/125\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 0.5299 - accuracy: 0.8687 - val_loss: 1.1350 - val_accuracy: 0.8714\n",
            "Epoch 58/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.5887 - accuracy: 0.8125 - val_loss: 1.2958 - val_accuracy: 0.8714\n",
            "Epoch 59/125\n",
            "5/5 [==============================] - 2s 456ms/step - loss: 0.4302 - accuracy: 0.8625 - val_loss: 0.0644 - val_accuracy: 0.9143\n",
            "Epoch 60/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.5065 - accuracy: 0.8125 - val_loss: 0.3040 - val_accuracy: 0.8857\n",
            "Epoch 61/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 0.3720 - accuracy: 0.8687 - val_loss: 0.8415 - val_accuracy: 0.8571\n",
            "Epoch 62/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.4197 - accuracy: 0.9125 - val_loss: 1.1160 - val_accuracy: 0.8714\n",
            "Epoch 63/125\n",
            "5/5 [==============================] - 2s 457ms/step - loss: 0.4784 - accuracy: 0.8625 - val_loss: 0.8531 - val_accuracy: 0.8714\n",
            "Epoch 64/125\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.3438 - accuracy: 0.9187 - val_loss: 0.0701 - val_accuracy: 0.9143\n",
            "Epoch 65/125\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.2016 - accuracy: 0.9500 - val_loss: 0.0060 - val_accuracy: 0.9286\n",
            "Epoch 66/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.2594 - accuracy: 0.9125 - val_loss: 0.9887 - val_accuracy: 0.9143\n",
            "Epoch 67/125\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.2745 - accuracy: 0.8938 - val_loss: 0.1235 - val_accuracy: 0.9000\n",
            "Epoch 68/125\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 0.3454 - accuracy: 0.8813 - val_loss: 0.0018 - val_accuracy: 0.8571\n",
            "Epoch 69/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.4077 - accuracy: 0.8938 - val_loss: 0.1041 - val_accuracy: 0.8571\n",
            "Epoch 70/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 0.5353 - accuracy: 0.8375 - val_loss: 0.9597 - val_accuracy: 0.8714\n",
            "Epoch 71/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.4891 - accuracy: 0.9000 - val_loss: 1.6672 - val_accuracy: 0.8714\n",
            "Epoch 72/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.3878 - accuracy: 0.8625 - val_loss: 0.0877 - val_accuracy: 0.9143\n",
            "Epoch 73/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.2979 - accuracy: 0.9161 - val_loss: 0.0857 - val_accuracy: 0.8571\n",
            "Epoch 74/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.4504 - accuracy: 0.8813 - val_loss: 0.2126 - val_accuracy: 0.9714\n",
            "Epoch 75/125\n",
            "5/5 [==============================] - 2s 454ms/step - loss: 0.2266 - accuracy: 0.9125 - val_loss: 0.3761 - val_accuracy: 0.9286\n",
            "Epoch 76/125\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 0.1366 - accuracy: 0.9625 - val_loss: 0.1724 - val_accuracy: 0.9429\n",
            "Epoch 77/125\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 0.2587 - accuracy: 0.9438 - val_loss: 0.0097 - val_accuracy: 0.9429\n",
            "Epoch 78/125\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.2449 - accuracy: 0.9312 - val_loss: 0.1662 - val_accuracy: 0.9286\n",
            "Epoch 79/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.2245 - accuracy: 0.9250 - val_loss: 0.1412 - val_accuracy: 0.9571\n",
            "Epoch 80/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 0.2013 - accuracy: 0.9563 - val_loss: 0.4958 - val_accuracy: 0.9571\n",
            "Epoch 81/125\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.1758 - accuracy: 0.9563 - val_loss: 0.2333 - val_accuracy: 0.9286\n",
            "Epoch 82/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.1079 - accuracy: 0.9563 - val_loss: 0.2302 - val_accuracy: 0.8857\n",
            "Epoch 83/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.1747 - accuracy: 0.9438 - val_loss: 0.0067 - val_accuracy: 0.9571\n",
            "Epoch 84/125\n",
            "5/5 [==============================] - 2s 466ms/step - loss: 0.2494 - accuracy: 0.9375 - val_loss: 0.1045 - val_accuracy: 1.0000\n",
            "Epoch 85/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.2614 - accuracy: 0.9375 - val_loss: 0.2071 - val_accuracy: 0.9286\n",
            "Epoch 86/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.2037 - accuracy: 0.9312 - val_loss: 0.0077 - val_accuracy: 0.9286\n",
            "Epoch 87/125\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.1837 - accuracy: 0.9301 - val_loss: 0.0072 - val_accuracy: 0.9000\n",
            "Epoch 88/125\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 0.2958 - accuracy: 0.9187 - val_loss: 0.2939 - val_accuracy: 0.9429\n",
            "Epoch 89/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.2046 - accuracy: 0.9438 - val_loss: 0.1143 - val_accuracy: 0.9429\n",
            "Epoch 90/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.1677 - accuracy: 0.9563 - val_loss: 2.2261 - val_accuracy: 0.9286\n",
            "Epoch 91/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.0960 - accuracy: 0.9750 - val_loss: 0.0457 - val_accuracy: 0.9571\n",
            "Epoch 92/125\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.1645 - accuracy: 0.9500 - val_loss: 0.0252 - val_accuracy: 0.9571\n",
            "Epoch 93/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.1580 - accuracy: 0.9187 - val_loss: 0.1895 - val_accuracy: 0.9286\n",
            "Epoch 94/125\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 0.1408 - accuracy: 0.9500 - val_loss: 0.4392 - val_accuracy: 0.9429\n",
            "Epoch 95/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.1129 - accuracy: 0.9688 - val_loss: 0.0290 - val_accuracy: 0.9429\n",
            "Epoch 96/125\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 1.2205e-04 - val_accuracy: 0.9286\n",
            "Epoch 97/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 0.1995 - accuracy: 0.9301 - val_loss: 0.0036 - val_accuracy: 0.9286\n",
            "Epoch 98/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.1289 - accuracy: 0.9688 - val_loss: 0.9202 - val_accuracy: 0.9000\n",
            "Epoch 99/125\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.2450 - accuracy: 0.9500 - val_loss: 0.2177 - val_accuracy: 0.9143\n",
            "Epoch 100/125\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 0.1048 - accuracy: 0.9625 - val_loss: 0.0042 - val_accuracy: 0.9000\n",
            "Epoch 101/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.0675 - accuracy: 0.9812 - val_loss: 0.0296 - val_accuracy: 0.9000\n",
            "Epoch 102/125\n",
            "5/5 [==============================] - 2s 452ms/step - loss: 0.1745 - accuracy: 0.9441 - val_loss: 0.0303 - val_accuracy: 0.9429\n",
            "Epoch 103/125\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.1750 - accuracy: 0.9500 - val_loss: 0.0071 - val_accuracy: 0.9286\n",
            "Epoch 104/125\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 0.0991 - accuracy: 0.9688 - val_loss: 1.0130 - val_accuracy: 0.9143\n",
            "Epoch 105/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.1744 - accuracy: 0.9438 - val_loss: 4.2031e-04 - val_accuracy: 0.9429\n",
            "Epoch 106/125\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 0.1493 - accuracy: 0.9625 - val_loss: 0.7611 - val_accuracy: 0.9000\n",
            "Epoch 107/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.2381 - accuracy: 0.9375 - val_loss: 1.8948 - val_accuracy: 0.9286\n",
            "Epoch 108/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.2577 - accuracy: 0.9375 - val_loss: 7.1814e-05 - val_accuracy: 0.9429\n",
            "Epoch 109/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.2305 - accuracy: 0.9312 - val_loss: 3.3176 - val_accuracy: 0.9000\n",
            "Epoch 110/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 0.2476 - accuracy: 0.9187 - val_loss: 1.3323 - val_accuracy: 0.9000\n",
            "Epoch 111/125\n",
            "5/5 [==============================] - 2s 462ms/step - loss: 0.3932 - accuracy: 0.8813 - val_loss: 1.0464 - val_accuracy: 0.9571\n",
            "Epoch 112/125\n",
            "5/5 [==============================] - 2s 453ms/step - loss: 0.2265 - accuracy: 0.9125 - val_loss: 0.8614 - val_accuracy: 0.9143\n",
            "Epoch 113/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.2873 - accuracy: 0.9062 - val_loss: 0.0569 - val_accuracy: 0.9571\n",
            "Epoch 114/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.2576 - accuracy: 0.9125 - val_loss: 0.0272 - val_accuracy: 0.9714\n",
            "Epoch 115/125\n",
            "5/5 [==============================] - 2s 464ms/step - loss: 0.1367 - accuracy: 0.9438 - val_loss: 0.4715 - val_accuracy: 0.9714\n",
            "Epoch 116/125\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.1053 - accuracy: 0.9688 - val_loss: 0.0969 - val_accuracy: 0.9714\n",
            "Epoch 117/125\n",
            "5/5 [==============================] - 2s 455ms/step - loss: 0.0705 - accuracy: 0.9720 - val_loss: 0.4359 - val_accuracy: 0.9286\n",
            "Epoch 118/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.2082 - accuracy: 0.9125 - val_loss: 0.0066 - val_accuracy: 0.9714\n",
            "Epoch 119/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.2066 - accuracy: 0.9312 - val_loss: 0.2068 - val_accuracy: 0.9143\n",
            "Epoch 120/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.3698 - accuracy: 0.9187 - val_loss: 0.8484 - val_accuracy: 0.8857\n",
            "Epoch 121/125\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.3545 - accuracy: 0.9125 - val_loss: 0.0081 - val_accuracy: 0.9143\n",
            "Epoch 122/125\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.1432 - accuracy: 0.9625 - val_loss: 7.6562e-04 - val_accuracy: 0.8714\n",
            "Epoch 123/125\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.4328 - accuracy: 0.9312 - val_loss: 1.1899 - val_accuracy: 0.9286\n",
            "Epoch 124/125\n",
            "5/5 [==============================] - 2s 457ms/step - loss: 0.1786 - accuracy: 0.9375 - val_loss: 0.0323 - val_accuracy: 0.9571\n",
            "Epoch 125/125\n",
            "5/5 [==============================] - 2s 449ms/step - loss: 0.1853 - accuracy: 0.9563 - val_loss: 0.8245 - val_accuracy: 0.9714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRgVaZNSgNuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(loss,val_loss):\n",
        "    plt.figure()\n",
        "    plt.plot(loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuracy(acc,val_acc):\n",
        "    plt.figure()\n",
        "    plt.plot(acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Test'],loc='upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGml1iUdlRui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_resnet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6e7USJ6lYjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}